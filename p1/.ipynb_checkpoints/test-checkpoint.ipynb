{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import tarfile\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import argparse\n",
    "from mapping import phone_maps\n",
    "import python_speech_features as psf\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "timit_phone_map = phone_maps(mapping_file=\"kaldi_60_48_39.map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(word):\n",
    "    # LC ALL & strip punctuation which are not required\n",
    "    new = word.lower().replace('.', '')\n",
    "    new = new.replace(',', '')\n",
    "    new = new.replace(';', '')\n",
    "    new = new.replace('\"', '')\n",
    "    new = new.replace('!', '')\n",
    "    new = new.replace('?', '')\n",
    "    new = new.replace(':', '')\n",
    "    new = new.replace('-', '')\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(wav_file, n_delta=0):\n",
    "    mfcc_feat = psf.mfcc(wav_file)\n",
    "    if(n_delta == 0):\n",
    "        return(mfcc_feat)\n",
    "    elif(n_delta == 1):\n",
    "        return(np.hstack((mfcc_feat, psf.delta(mfcc_feat,1))))\n",
    "    elif(n_delta == 2):\n",
    "        return(np.hstack((mfcc_feat, psf.delta(mfcc_feat,1), psf.delta(mfcc_feat, 2))))\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transcript(full_wav):\n",
    "    trans_file = full_wav[:-8] + \".PHN\"\n",
    "    with open(trans_file, \"r\") as file:\n",
    "        trans = file.readlines()\n",
    "    durations = [ele.strip().split(\" \")[:-1] for ele in trans]\n",
    "    durations_int = []\n",
    "    for duration in durations:\n",
    "        durations_int.append([int(duration[0]), int(duration[1])])\n",
    "    trans = [ele.strip().split(\" \")[-1] for ele in trans]\n",
    "    trans = [timit_phone_map.map_symbol_reduced(symbol=phoneme) for phoneme in trans]\n",
    "    # trans = \" \".join(trans)\n",
    "    return trans, durations_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_data(args):\n",
    "    target = args.timit\n",
    "    preprocessed = args.preprocessed\n",
    "    print(\"Preprocessing data\")\n",
    "    print(preprocessed)\n",
    "    \n",
    "    n_delta = int(args.n_delta)\n",
    "    path = 'mfcc'\n",
    "    if n_delta==1:\n",
    "        path = 'mfcc_delta'\n",
    "    elif n_delta==2:\n",
    "        path = 'mfcc_delta_delta'\n",
    "        \n",
    "    # Assume data is downloaded from LDC - https://catalog.ldc.upenn.edu/ldc93s1\n",
    "    # We convert the .WAV (NIST sphere format) into MSOFT .wav\n",
    "    # creates _rif.wav as the new .wav file\n",
    "    if(preprocessed):\n",
    "        print(\"Data is already preprocessed, just gonna read it\")\n",
    "    full_wavs = []\n",
    "    for root, dirnames, filenames in os.walk(target):\n",
    "        for filename in fnmatch.filter(filenames, \"*.WAV\"):\n",
    "            sph_file = os.path.join(root, filename)\n",
    "            wav_file = os.path.join(root, filename)[:-4] + \"_rif.wav\"\n",
    "            full_wavs.append(wav_file)\n",
    "            print(\"converting {} to {}\".format(sph_file, wav_file))\n",
    "            if(~preprocessed):\n",
    "                subprocess.check_call([\"sox\", sph_file, wav_file])\n",
    "\n",
    "    print(\"Preprocessing Complete\")\n",
    "    print(\"Building features\")\n",
    "\n",
    "    mfcc_features = []\n",
    "    mfcc_labels = []\n",
    "\n",
    "    # with open(\"train_wavs\", \"r\") as file:\n",
    "    #     full_wavs = file.readlines()\n",
    "    # full_wavs = [ele.strip() for ele in full_wavs]\n",
    "\n",
    "    for full_wav in full_wavs:\n",
    "        print(\"Computing features for file: \", full_wav)\n",
    "\n",
    "        trans, durations = read_transcript(full_wav = full_wav)\n",
    "        n_delta = int(args.n_delta)\n",
    "        labels = []\n",
    "\n",
    "        (sample_rate,wav_file) = wav.read(full_wav)\n",
    "        mfcc_feats = compute_mfcc(wav_file[durations[0][0]:durations[0][1]], n_delta=n_delta)\n",
    "\n",
    "        for i in range(len(mfcc_feats)):\n",
    "            labels.append(trans[0])\n",
    "        for index, chunk in enumerate(durations[1:]):\n",
    "            mfcc_feat = compute_mfcc(wav_file[chunk[0]:chunk[1]], n_delta=n_delta)\n",
    "            mfcc_feats = np.vstack((mfcc_feats, mfcc_feat))\n",
    "            for i in range(len(mfcc_feat)):\n",
    "                labels.append(trans[index])\n",
    "        mfcc_features.extend(mfcc_feats)\n",
    "        mfcc_labels.extend(labels)\n",
    "    \n",
    "    #Feature extraction\n",
    "    mfcc_labels = np.array(mfcc_labels)\n",
    "    phonemes = list(set(mfcc_labels))\n",
    "    mfcc_features = np.array(mfcc_features)\n",
    "    l = ['i','ii'] \n",
    "    \n",
    "    for ele in l:\n",
    "        dir_list = os.listdir(path='./models/'+path+\"/\"+ele)\n",
    "        for dir_path in dir_list:\n",
    "            for phoneme in phonemes:\n",
    "                gmm = joblib.load(\"./models/\"+path+\"/\"+ele+\"/\"+dir_path+\"/phn_\"+phoneme)\n",
    "    \n",
    "    for phoneme in phonemes:\n",
    "        indices = np.where(mfcc_labels==phoneme)\n",
    "        phoneme_features = []\n",
    "        for index in indices:\n",
    "            phoneme_features.append(mfcc_features[index])\n",
    "        phoneme_df = pd.DataFrame()\n",
    "        phoneme_df['features'] = phoneme_features\n",
    "        phoneme_df.to_hdf(\"./features/\"+path+\"/phoneme_wise/phn_\"+phoneme+\".hdf\",\"phn_\"+phoneme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--timit', type=str, default=\"./TIMIT/TEST\",\n",
    "                       help='TIMIT root directory')\n",
    "    parser.add_argument('--n_delta', type=str, default=\"0\",\n",
    "                       help='Number of delta features to compute')\n",
    "    parser.add_argument('--preprocessed', type=bool, default=False,\n",
    "                       help='Set to True if already preprocessed')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    print(\"TIMIT path is: \", args.timit)\n",
    "    _preprocess_data(args)\n",
    "    print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
